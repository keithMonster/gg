#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ggæ™ºèƒ½ä½“æ€§èƒ½ç›‘æ§ç³»ç»Ÿ

åŠŸèƒ½:
- å®æ—¶ç›‘æ§ä»»åŠ¡æ‰§è¡Œæ€§èƒ½
- æ”¶é›†å’Œåˆ†ææ€§èƒ½æŒ‡æ ‡
- ç”Ÿæˆæ€§èƒ½æŠ¥å‘Šå’Œä¼˜åŒ–å»ºè®®
- æ£€æµ‹æ€§èƒ½å¼‚å¸¸å’Œç“¶é¢ˆ
"""

import json
import time
import psutil
import threading
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, asdict
from collections import defaultdict, deque

@dataclass
class PerformanceMetric:
    """æ€§èƒ½æŒ‡æ ‡æ•°æ®ç»“æ„"""
    timestamp: str
    metric_type: str
    value: float
    unit: str
    context: Dict[str, Any]
    session_id: str

@dataclass
class TaskPerformance:
    """ä»»åŠ¡æ€§èƒ½æ•°æ®ç»“æ„"""
    task_id: str
    task_type: str
    start_time: str
    end_time: Optional[str]
    duration_ms: Optional[float]
    cpu_usage: float
    memory_usage: float
    success: Optional[bool]
    error_message: Optional[str]
    metrics: List[PerformanceMetric]

class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨"""
    
    def __init__(self, config_path: str = "config/performance_config.json"):
        self.config_path = Path(config_path)
        self.metrics_dir = Path("metrics")
        self.metrics_dir.mkdir(exist_ok=True)
        
        # åŠ è½½é…ç½®
        self.config = self.load_config()
        
        # æ€§èƒ½æ•°æ®å­˜å‚¨
        self.current_tasks: Dict[str, TaskPerformance] = {}
        self.metrics_buffer = deque(maxlen=self.config.get('buffer_size', 1000))
        self.session_id = f"session_{int(time.time())}"
        
        # ç›‘æ§çº¿ç¨‹
        self.monitoring = False
        self.monitor_thread = None
        
        # æ€§èƒ½ç»Ÿè®¡
        self.stats = {
            'total_tasks': 0,
            'successful_tasks': 0,
            'failed_tasks': 0,
            'avg_duration': 0.0,
            'avg_cpu_usage': 0.0,
            'avg_memory_usage': 0.0
        }
    
    def load_config(self) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        if self.config_path.exists():
            with open(self.config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        else:
            # é»˜è®¤é…ç½®
            default_config = {
                'monitoring_interval': 1.0,  # ç§’
                'buffer_size': 1000,
                'alert_thresholds': {
                    'cpu_usage': 80.0,
                    'memory_usage': 80.0,
                    'task_duration': 30000  # æ¯«ç§’
                },
                'metrics_retention_days': 7,
                'auto_cleanup': True
            }
            # ä¿å­˜é»˜è®¤é…ç½®
            self.config_path.parent.mkdir(exist_ok=True)
            with open(self.config_path, 'w', encoding='utf-8') as f:
                json.dump(default_config, f, indent=2, ensure_ascii=False)
            return default_config
    
    def start_monitoring(self):
        """å¼€å§‹æ€§èƒ½ç›‘æ§"""
        if not self.monitoring:
            self.monitoring = True
            self.monitor_thread = threading.Thread(target=self._monitor_loop, daemon=True)
            self.monitor_thread.start()
            print(f"[PERF] æ€§èƒ½ç›‘æ§å·²å¯åŠ¨ (ä¼šè¯ID: {self.session_id})")
    
    def stop_monitoring(self):
        """åœæ­¢æ€§èƒ½ç›‘æ§"""
        if self.monitoring:
            self.monitoring = False
            if self.monitor_thread:
                self.monitor_thread.join(timeout=2.0)
            self.save_metrics()
            print("[PERF] æ€§èƒ½ç›‘æ§å·²åœæ­¢")
    
    def _monitor_loop(self):
        """ç›‘æ§å¾ªç¯"""
        interval = self.config.get('monitoring_interval', 1.0)
        
        while self.monitoring:
            try:
                # æ”¶é›†ç³»ç»ŸæŒ‡æ ‡
                cpu_percent = psutil.cpu_percent()
                memory_info = psutil.virtual_memory()
                
                # è®°å½•ç³»ç»ŸæŒ‡æ ‡
                self.record_metric(
                    metric_type="system_cpu",
                    value=cpu_percent,
                    unit="percent",
                    context={"cores": psutil.cpu_count()}
                )
                
                self.record_metric(
                    metric_type="system_memory",
                    value=memory_info.percent,
                    unit="percent",
                    context={
                        "total_gb": round(memory_info.total / (1024**3), 2),
                        "available_gb": round(memory_info.available / (1024**3), 2)
                    }
                )
                
                # æ£€æŸ¥å‘Šè­¦é˜ˆå€¼
                self._check_alerts(cpu_percent, memory_info.percent)
                
                time.sleep(interval)
                
            except Exception as e:
                print(f"[PERF] ç›‘æ§å¾ªç¯é”™è¯¯: {e}")
                time.sleep(interval)
    
    def start_task(self, task_id: str, task_type: str) -> str:
        """å¼€å§‹ä»»åŠ¡ç›‘æ§"""
        task_perf = TaskPerformance(
            task_id=task_id,
            task_type=task_type,
            start_time=datetime.now().isoformat(),
            end_time=None,
            duration_ms=None,
            cpu_usage=psutil.cpu_percent(),
            memory_usage=psutil.virtual_memory().percent,
            success=None,
            error_message=None,
            metrics=[]
        )
        
        self.current_tasks[task_id] = task_perf
        print(f"[PERF] å¼€å§‹ç›‘æ§ä»»åŠ¡: {task_id} ({task_type})")
        return task_id
    
    def end_task(self, task_id: str, success: bool = True, error_message: Optional[str] = None):
        """ç»“æŸä»»åŠ¡ç›‘æ§"""
        if task_id not in self.current_tasks:
            print(f"[PERF] è­¦å‘Š: ä»»åŠ¡ {task_id} æœªæ‰¾åˆ°")
            return
        
        task_perf = self.current_tasks[task_id]
        end_time = datetime.now()
        start_time = datetime.fromisoformat(task_perf.start_time)
        
        task_perf.end_time = end_time.isoformat()
        task_perf.duration_ms = (end_time - start_time).total_seconds() * 1000
        task_perf.success = success
        task_perf.error_message = error_message
        
        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        self._update_stats(task_perf)
        
        # ä¿å­˜ä»»åŠ¡æ€§èƒ½æ•°æ®
        self._save_task_performance(task_perf)
        
        # ä»å½“å‰ä»»åŠ¡ä¸­ç§»é™¤
        del self.current_tasks[task_id]
        
        print(f"[PERF] ä»»åŠ¡å®Œæˆ: {task_id} (è€—æ—¶: {task_perf.duration_ms:.1f}ms)")
    
    def record_metric(self, metric_type: str, value: float, unit: str, context: Optional[Dict] = None):
        """è®°å½•æ€§èƒ½æŒ‡æ ‡"""
        metric = PerformanceMetric(
            timestamp=datetime.now().isoformat(),
            metric_type=metric_type,
            value=value,
            unit=unit,
            context=context or {},
            session_id=self.session_id
        )
        
        self.metrics_buffer.append(metric)
    
    def _check_alerts(self, cpu_percent: float, memory_percent: float):
        """æ£€æŸ¥å‘Šè­¦é˜ˆå€¼"""
        thresholds = self.config.get('alert_thresholds', {})
        
        if cpu_percent > thresholds.get('cpu_usage', 80):
            print(f"[PERF] ğŸš¨ CPUä½¿ç”¨ç‡å‘Šè­¦: {cpu_percent:.1f}%")
        
        if memory_percent > thresholds.get('memory_usage', 80):
            print(f"[PERF] ğŸš¨ å†…å­˜ä½¿ç”¨ç‡å‘Šè­¦: {memory_percent:.1f}%")
    
    def _update_stats(self, task_perf: TaskPerformance):
        """æ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        self.stats['total_tasks'] += 1
        
        if task_perf.success:
            self.stats['successful_tasks'] += 1
        else:
            self.stats['failed_tasks'] += 1
        
        # è®¡ç®—å¹³å‡å€¼
        total = self.stats['total_tasks']
        if task_perf.duration_ms:
            self.stats['avg_duration'] = (
                (self.stats['avg_duration'] * (total - 1) + task_perf.duration_ms) / total
            )
        
        self.stats['avg_cpu_usage'] = (
            (self.stats['avg_cpu_usage'] * (total - 1) + task_perf.cpu_usage) / total
        )
        
        self.stats['avg_memory_usage'] = (
            (self.stats['avg_memory_usage'] * (total - 1) + task_perf.memory_usage) / total
        )
    
    def _save_task_performance(self, task_perf: TaskPerformance):
        """ä¿å­˜ä»»åŠ¡æ€§èƒ½æ•°æ®"""
        date_str = datetime.now().strftime('%Y-%m-%d')
        file_path = self.metrics_dir / f"tasks_{date_str}.jsonl"
        
        with open(file_path, 'a', encoding='utf-8') as f:
            f.write(json.dumps(asdict(task_perf), ensure_ascii=False) + '\n')
    
    def save_metrics(self):
        """ä¿å­˜æŒ‡æ ‡æ•°æ®"""
        if not self.metrics_buffer:
            return
        
        date_str = datetime.now().strftime('%Y-%m-%d')
        file_path = self.metrics_dir / f"metrics_{date_str}.jsonl"
        
        with open(file_path, 'a', encoding='utf-8') as f:
            for metric in self.metrics_buffer:
                f.write(json.dumps(asdict(metric), ensure_ascii=False) + '\n')
        
        self.metrics_buffer.clear()
    
    def get_performance_report(self, days: int = 1) -> Dict[str, Any]:
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days)
        
        # è¯»å–æŒ‡å®šæ—¶é—´èŒƒå›´å†…çš„æ•°æ®
        tasks_data = self._load_tasks_data(start_date, end_date)
        metrics_data = self._load_metrics_data(start_date, end_date)
        
        # åˆ†ææ•°æ®
        report = {
            'report_period': {
                'start': start_date.isoformat(),
                'end': end_date.isoformat(),
                'days': days
            },
            'task_summary': self._analyze_tasks(tasks_data),
            'system_metrics': self._analyze_metrics(metrics_data),
            'performance_trends': self._analyze_trends(tasks_data, metrics_data),
            'recommendations': self._generate_recommendations(tasks_data, metrics_data),
            'current_stats': self.stats
        }
        
        return report
    
    def _load_tasks_data(self, start_date: datetime, end_date: datetime) -> List[Dict]:
        """åŠ è½½ä»»åŠ¡æ•°æ®"""
        tasks = []
        current_date = start_date.date()
        
        while current_date <= end_date.date():
            file_path = self.metrics_dir / f"tasks_{current_date.strftime('%Y-%m-%d')}.jsonl"
            if file_path.exists():
                with open(file_path, 'r', encoding='utf-8') as f:
                    for line in f:
                        task_data = json.loads(line.strip())
                        task_time = datetime.fromisoformat(task_data['start_time'])
                        if start_date <= task_time <= end_date:
                            tasks.append(task_data)
            current_date += timedelta(days=1)
        
        return tasks
    
    def _load_metrics_data(self, start_date: datetime, end_date: datetime) -> List[Dict]:
        """åŠ è½½æŒ‡æ ‡æ•°æ®"""
        metrics = []
        current_date = start_date.date()
        
        while current_date <= end_date.date():
            file_path = self.metrics_dir / f"metrics_{current_date.strftime('%Y-%m-%d')}.jsonl"
            if file_path.exists():
                with open(file_path, 'r', encoding='utf-8') as f:
                    for line in f:
                        metric_data = json.loads(line.strip())
                        metric_time = datetime.fromisoformat(metric_data['timestamp'])
                        if start_date <= metric_time <= end_date:
                            metrics.append(metric_data)
            current_date += timedelta(days=1)
        
        return metrics
    
    def _analyze_tasks(self, tasks_data: List[Dict]) -> Dict[str, Any]:
        """åˆ†æä»»åŠ¡æ•°æ®"""
        if not tasks_data:
            return {'total_tasks': 0}
        
        total_tasks = len(tasks_data)
        successful_tasks = sum(1 for task in tasks_data if task.get('success', False))
        failed_tasks = total_tasks - successful_tasks
        
        durations = [task['duration_ms'] for task in tasks_data if task.get('duration_ms')]
        avg_duration = sum(durations) / len(durations) if durations else 0
        
        task_types = defaultdict(int)
        for task in tasks_data:
            task_types[task['task_type']] += 1
        
        return {
            'total_tasks': total_tasks,
            'successful_tasks': successful_tasks,
            'failed_tasks': failed_tasks,
            'success_rate': successful_tasks / total_tasks if total_tasks > 0 else 0,
            'avg_duration_ms': avg_duration,
            'task_types': dict(task_types),
            'slowest_tasks': sorted(tasks_data, key=lambda x: x.get('duration_ms', 0), reverse=True)[:5]
        }
    
    def _analyze_metrics(self, metrics_data: List[Dict]) -> Dict[str, Any]:
        """åˆ†æç³»ç»ŸæŒ‡æ ‡"""
        if not metrics_data:
            return {}
        
        cpu_metrics = [m for m in metrics_data if m['metric_type'] == 'system_cpu']
        memory_metrics = [m for m in metrics_data if m['metric_type'] == 'system_memory']
        
        analysis = {}
        
        if cpu_metrics:
            cpu_values = [m['value'] for m in cpu_metrics]
            analysis['cpu'] = {
                'avg': sum(cpu_values) / len(cpu_values),
                'max': max(cpu_values),
                'min': min(cpu_values),
                'samples': len(cpu_values)
            }
        
        if memory_metrics:
            memory_values = [m['value'] for m in memory_metrics]
            analysis['memory'] = {
                'avg': sum(memory_values) / len(memory_values),
                'max': max(memory_values),
                'min': min(memory_values),
                'samples': len(memory_values)
            }
        
        return analysis
    
    def _analyze_trends(self, tasks_data: List[Dict], metrics_data: List[Dict]) -> Dict[str, Any]:
        """åˆ†ææ€§èƒ½è¶‹åŠ¿"""
        # ç®€åŒ–çš„è¶‹åŠ¿åˆ†æ
        trends = {
            'task_frequency': 'stable',  # å¯ä»¥åŸºäºæ—¶é—´åˆ†å¸ƒè®¡ç®—
            'performance_trend': 'stable',  # å¯ä»¥åŸºäºdurationå˜åŒ–è®¡ç®—
            'resource_usage': 'normal'  # å¯ä»¥åŸºäºCPU/å†…å­˜ä½¿ç”¨ç‡è®¡ç®—
        }
        
        return trends
    
    def _generate_recommendations(self, tasks_data: List[Dict], metrics_data: List[Dict]) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        # åŸºäºä»»åŠ¡åˆ†æçš„å»ºè®®
        if tasks_data:
            avg_duration = sum(task.get('duration_ms', 0) for task in tasks_data) / len(tasks_data)
            if avg_duration > 10000:  # 10ç§’
                recommendations.append("ä»»åŠ¡å¹³å‡æ‰§è¡Œæ—¶é—´è¾ƒé•¿ï¼Œå»ºè®®ä¼˜åŒ–ä»»åŠ¡æ‰§è¡Œé€»è¾‘")
            
            failed_rate = sum(1 for task in tasks_data if not task.get('success', True)) / len(tasks_data)
            if failed_rate > 0.1:  # 10%å¤±è´¥ç‡
                recommendations.append("ä»»åŠ¡å¤±è´¥ç‡è¾ƒé«˜ï¼Œå»ºè®®æ£€æŸ¥é”™è¯¯å¤„ç†æœºåˆ¶")
        
        # åŸºäºç³»ç»ŸæŒ‡æ ‡çš„å»ºè®®
        cpu_metrics = [m for m in metrics_data if m['metric_type'] == 'system_cpu']
        if cpu_metrics:
            avg_cpu = sum(m['value'] for m in cpu_metrics) / len(cpu_metrics)
            if avg_cpu > 70:
                recommendations.append("CPUä½¿ç”¨ç‡è¾ƒé«˜ï¼Œå»ºè®®ä¼˜åŒ–è®¡ç®—å¯†é›†å‹æ“ä½œ")
        
        memory_metrics = [m for m in metrics_data if m['metric_type'] == 'system_memory']
        if memory_metrics:
            avg_memory = sum(m['value'] for m in memory_metrics) / len(memory_metrics)
            if avg_memory > 70:
                recommendations.append("å†…å­˜ä½¿ç”¨ç‡è¾ƒé«˜ï¼Œå»ºè®®ä¼˜åŒ–å†…å­˜ç®¡ç†")
        
        if not recommendations:
            recommendations.append("ç³»ç»Ÿæ€§èƒ½è‰¯å¥½ï¼Œç»§ç»­ä¿æŒ")
        
        return recommendations
    
    def monitor_command(self, command):
        """ç›‘æ§å‘½ä»¤æ‰§è¡Œ"""
        import subprocess
        import time
        
        print(f"[PERF] å¼€å§‹ç›‘æ§å‘½ä»¤: {command}")
        
        start_time = time.time()
        start_cpu = psutil.cpu_percent()
        start_memory = psutil.virtual_memory().percent
        
        try:
            # æ‰§è¡Œå‘½ä»¤
            result = subprocess.run(command, shell=True, capture_output=True, text=True)
            
            end_time = time.time()
            end_cpu = psutil.cpu_percent()
            end_memory = psutil.virtual_memory().percent
            
            # è®¡ç®—æ€§èƒ½å·®å¼‚
            execution_time = end_time - start_time
            cpu_usage_change = end_cpu - start_cpu
            memory_usage_change = end_memory - start_memory
            
            # è®°å½•ç›‘æ§ç»“æœ
            monitoring_result = {
                "command": command,
                "execution_time": execution_time,
                "cpu_usage_change": cpu_usage_change,
                "memory_usage_change": memory_usage_change,
                "exit_code": result.returncode,
                "stdout": result.stdout,
                "stderr": result.stderr,
                "timestamp": datetime.now().isoformat()
            }
            
            print(f"[PERF] å‘½ä»¤ç›‘æ§å®Œæˆ: {execution_time:.2f}s")
            return monitoring_result
            
        except Exception as e:
            print(f"[PERF] å‘½ä»¤ç›‘æ§å¤±è´¥: {e}")
            return None

# å…¨å±€ç›‘æ§å™¨å®ä¾‹
_monitor_instance = None

def get_monitor() -> PerformanceMonitor:
    """è·å–å…¨å±€ç›‘æ§å™¨å®ä¾‹"""
    global _monitor_instance
    if _monitor_instance is None:
        _monitor_instance = PerformanceMonitor()
    return _monitor_instance

def start_monitoring():
    """å¯åŠ¨æ€§èƒ½ç›‘æ§"""
    monitor = get_monitor()
    monitor.start_monitoring()

def stop_monitoring():
    """åœæ­¢æ€§èƒ½ç›‘æ§"""
    monitor = get_monitor()
    monitor.stop_monitoring()

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="ggæ™ºèƒ½ä½“æ€§èƒ½ç›‘æ§ç³»ç»Ÿ")
    parser.add_argument('action', choices=['start', 'stop', 'report', 'status'],
                       help='æ‰§è¡Œçš„æ“ä½œ')
    parser.add_argument('--days', type=int, default=1,
                       help='æŠ¥å‘Šæ—¶é—´èŒƒå›´(å¤©)')
    parser.add_argument('--output', type=str,
                       help='æŠ¥å‘Šè¾“å‡ºæ–‡ä»¶è·¯å¾„')
    
    args = parser.parse_args()
    
    monitor = PerformanceMonitor()
    
    if args.action == 'start':
        monitor.start_monitoring()
        try:
            # ä¿æŒç›‘æ§è¿è¡Œ
            while True:
                time.sleep(1)
        except KeyboardInterrupt:
            monitor.stop_monitoring()
    
    elif args.action == 'stop':
        monitor.stop_monitoring()
    
    elif args.action == 'report':
        report = monitor.get_performance_report(days=args.days)
        
        if args.output:
            with open(args.output, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
            print(f"æŠ¥å‘Šå·²ä¿å­˜åˆ°: {args.output}")
        else:
            print(json.dumps(report, indent=2, ensure_ascii=False))
    
    elif args.action == 'status':
        print(f"å½“å‰ç»Ÿè®¡: {json.dumps(monitor.stats, indent=2, ensure_ascii=False)}")
        print(f"æ´»è·ƒä»»åŠ¡æ•°: {len(monitor.current_tasks)}")
        print(f"ç¼“å­˜æŒ‡æ ‡æ•°: {len(monitor.metrics_buffer)}")